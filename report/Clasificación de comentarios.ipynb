{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clasificación de comentarios\n",
    "Víctor Daniel Cruz González"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Objetivo\n",
    "Establecer un ambiente de comunicación seguro y de calidad para los usuarios\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Contexto\n",
    "\n",
    "Para este proyecto, requiero de tener una plataforma web capaz de indicar qué tan bueno o malo es un comentario, basándome en un modelo de Recurrent Neuronal Network que detallaré más adelante.\n",
    "\n",
    "Esta plataforma es un sitio de recetas en el que los usuarios pueden compartir videos y sus recetarios. Adicionalmente, otros pueden comentar cualquier cosa sobre esta. Sin embargo, se prohibe el uso de lenguaje ofensivo al momento de comentar. Por ende, la red neuronal sirve para detectar estos casos y permitir o no mandar el mensaje."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Antecedentes\n",
    "\n",
    "## Recurrent Neuronal Network\n",
    "Una red neuronal recurrente (RNN) es un tipo de red neuronal que utiliza datos secuenciales o series de tiempo. Estos algoritmos de aprendizaje profundo se utilizan para problemas temporales, como la traducción de idiomas, el procesamiento del lenguaje natural (nlp) o el reconocimiento de voz.\n",
    "\n",
    "![Unrolled network](unrolled-network.png)\n",
    "\n",
    "Mientras que las redes neuronales profundas asumen que las entradas y salidas son independientes entre sí, la salida de las recurrentes depende de los elementos anteriores. Asimismo, comparten parámetros en cada capa de la red. Las redes neuronales recurrentes comparten el mismo parámetro de peso dentro de cada capa de la red. Estos pesos todavía se ajustan en los procesos de retropropagación y descenso de gradiente para facilitar el aprendizaje por refuerzo.\n",
    "\n",
    "Las redes neuronales recurrentes aprovechan el algoritmo de retropropagación a través del tiempo (BPTT) para determinar los gradientes, pues es específico de los datos de secuencia. Este algoritmo implica que el modelo se entrena a sí mismo calculando errores desde su capa de salida hasta su capa de entrada. Estos cálculos nos permiten ajustar los parámetros del modelo. BPTT se diferencia del enfoque tradicional en que BPTT suma los errores en cada paso de tiempo, mientras que las redes de retroalimentación no necesitan sumar errores, ya que no comparten parámetros en cada capa.\n",
    "\n",
    "![BPPT](bptt.svg)\n",
    "\n",
    "A través de este proceso, los RNN tienen dos retos, conocidos como gradientes explosivos y gradientes que desaparecen. Estos problemas se definen por el tamaño del gradiente. Cuando el gradiente es demasiado pequeño, continúa haciéndolo más pequeño, actualizando los parámetros de peso hasta que se vuelven 0. Cuando eso ocurre, el algoritmo ya no está aprendiendo. Los gradientes explosivos se producen cuando el xambio de valor es demasiado grande, creando un modelo inestable. En este caso, los pesos del modelo crecerán demasiado, hasta números que sobrepasan las librerías de las computadoras. Una solución a estos problemas es reducir la cantidad de capas ocultas dentro de la red neuronal, eliminando parte de la complejidad del modelo RNN."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Arquitectura\n",
    "\n",
    "Dado que es una plataforma web, en este projecto use Node.js y Python para establecer la comunicación y la RNN. Específicamente, Tensorflow ayudo a esto y Flask a establecer comunicación entre Node.js y el modelo. Para hacerlo en un ambiente controlado, elegí Docker y Docker Compose."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Implementación"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Inicializando librerias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraphs(history, metric):\n",
    "    \"\"\"\n",
    "    Display graph of history and metric\n",
    "    \"\"\"\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_' + metric], '')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val' + metric])"
   ]
  },
  {
   "source": [
    "Obteniendo dataset de IMDB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load(\n",
    "    'imdb_reviews', with_info=True, as_supervised=True)\n",
    "trainDataset, testDataset = dataset['train'], dataset['test']\n",
    "print(trainDataset.element_spec)"
   ]
  },
  {
   "source": [
    "Generando ejemplo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\nlabel:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in trainDataset.take(1):\n",
    "    print('text: ', example.numpy())\n",
    "    print('label: ', label.numpy())"
   ]
  },
  {
   "source": [
    "Mezclando los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "texts:  [b'had some lovely poetic bits but is really just an artsy-fartsy toss-together with no direction or resolution. how do these people get through film school? who gives them money to make this crap? could have been so much more, fine lead actor, and i always like Fairuza Balk, but come on, the alt-rock metaphor of just staring vacantly unable to find anything compelling is just so tired, and it sure doesn\\'t make for good films. the director needs to go away and live life for a good long while and not come back to the camera until they really have something to say. this is like the throw-spaghetti-at-the-wall school of art-making, just juxtapose a bunch of earnest imagery and hope hope hope like hell that poetry emerges. that can work, if the director actually has any kind of vision, or has a brain that knows when it\\'s in the presence of potential, but here it\\'s just space filler, of no consequence. i felt the lazy ending coming moments before it hit, and was yelling \"you lazy bastard\" at the screen when the credits popped up.'\n b'What a horrible comedy. Totally lame. The supposed \"humor\" was simple and stupid. Stanly Tucci (a great actor) had the only parts worth chuckling at. And he was tied up and gagged at the time. Don\\'t waste your time with this one. It deserves a 0/10.'\n b'Written by a woman, and directed by another. Whoppie. Are we in for a feminist ride or what. Fasten your seat-belts, ladies, for we are about to enter a world of mean men and innocent, well-intentioned women.<br /><br />In this soaper Trish comes across a guy in the employment agency who behaves, looks, and dresses like a pimp(!) and gives her a job with the hope of nailing her some time later. In his office he even touches her chin the way a megalomaniacal heavy in a Bond movie would a touch a girl just after he\\'s captured her and just before he is ready to kill her alongside with Bond. Some time later the pimp/employment guy stalks Trish in a ladies\\' dressing-room, harasses her, and even comes close to raping her. Oh, these evil, evil men. They are ALL bad, don\\'t you know. You can\\'t even look for a job nowadays without getting raped, right ladies? Well, we\\'ll show \\'em! In this film there is some kind of a divorced women\\'s club or something, headed by a Janet Leigh who speaks for all women involved in this film when she says that \"men are all s**t\". She moans about how terrible men are; she has been divorced five times. Now, seriously: any woman who marries twenty times and then uses that statistic as an argument that men are all \"bad\" must have realized eventually that the explanation might lie elsewhere, or? It must occur to her that: a) she is a bad judge of male character, or - much more likely - b) SHE is the one impossible to live with - her ex-husbands were probably the victims, or if they were indeed a**holes then she probably got what she deserved. (Don\\'t the likes of Zsa-Zsa Gabor and Liz Taylor prove this point? Show me a likable woman who got married this often and I\\'ll show you a way to reach the planet Mars using only roller-skates and a ladder.) Trish eventually meets a computer guy who restores her faith in men - but hold your horses; this guy turns out to be married, therefore proving WITHOUT a doubt that men are indeed all \"bad\". Were it not, of course, for a kindly old vegetable seller around the corner who loves his wife even though she\\'s still dead - proving that all men are \"bad\" except for kindly old men whose penises don\\'t work and they \"can\\'t get none\" anyway so they are forced to abandon a life of a**holocolism and finally give women the respect they deserve. Even the supporting male characters are all \"bad\"; the black guy in the employment agency is unfriendly, and the guy in the mortuary is out-right rude - and insensitive (the bastard, *sob*...*sniffle*\\xc2\\x85) And what\\'s with this corny, corny ending?... Minutes before court-time Trish abandons the claim to any of her husband\\'s money, realizing that she is now \"free\" and that she can finally do that jump into the swimming pool...?? What\\'s all that about?? Her jump into the pool is then - very predictably - frame-frozen as the credits start to role in, while life-inspiring I-don\\'t-need-revenge-nor-my-husband\\'s-money music starts kicking in. Her girlfriends are shocked by her abandonment of money claims, but they don\\'t stay shocked for long and soon start kidding each other about what a heart-attack Trish\\'s lawyer will get when he hears about this. The shyster lawyer is naturally a man. An evil, evil, terrible \"bad\" man, whose only interest in this world is money... Ah, these men; all they care about is money; they know nothing of the higher values in life - like shopping. I am glad we have movies like this; they bring the sexes closer together, but most importantly, they teach girls and young women that men are all horny, selfish, skirt-chasing bastards who will dump you into a world of poverty and misery the first chance they get. So, girls, open your mouths an stick your tongues into your girlfriend\\'s mouths. Lesbian power!']\n\nlabels:  [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "trainDataset = trainDataset.shuffle(BUFFER_SIZE).batch(\n",
    "    BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "testDataset = testDataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for example, label in trainDataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "source": [
    "Creando text encoder\n",
    "\n",
    "Esto implica que el TextVectorization cambia y etique las palabras para que después sean usadas para el modelo. Hay que notar que los UNK se generan cuando el tamaño limitado del vocabulario y hay una falta de backup sobre los caracteres."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['' '[UNK]' 'the' 'and' 'a' 'of' 'to' 'is' 'in' 'it' 'i' 'this' 'that'\n 'br' 'was' 'as' 'for' 'with' 'movie' 'but']\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(trainDataset.map(lambda text, label: text))\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(vocab[:20])"
   ]
  },
  {
   "source": [
    "Mostrando ejemplos del encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  1  11 729 ...   0   0   0]\n [297   1  88 ...   0   0   0]\n [  1  14   4 ...   0   0   0]]\nOriginal:  b'Everyone is either loving or hating this film. I am going with loving. It is so well shot and so well acted. Beautiful. This film is for people who appreciate well crafted film making. If you are not a fan of well done films of course you would hate this. But if you like the tops of acting, photography, story and development, look no further then here.'\nRound-trip:  everyone is either [UNK] or [UNK] this film i am going with [UNK] it is so well shot and so well [UNK] beautiful this film is for people who [UNK] well [UNK] film making if you are not a fan of well done films of course you would hate this but if you like the [UNK] of acting [UNK] story and development look no [UNK] then here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\nOriginal:  b\"0.5/10. This movie has absolutely nothing good about it. The acting is among the worst I have ever seen, what is really amazing is that EVERYONE is awful, not just a few here and there, everyone. The direction is a joke, the low budget is hopelessly evident, the score is awful, I wouldn't say the movie was edited, brutally chopped would be a more appropriate phrase. It combines serial killings, voodoo and tarot cards. Dumb. Dumb. Dumb. It is not scary at all, the special effects are hopelessly lame. laughably bad throughout. The writing was appallingly bad. The cinematography is real cheap looking, and very grainy sometimes, and the camera-work is dreadful. Again, what really does the movie in is how badly all the actors are. Cheesy.\"\nRound-trip:  [UNK] this movie has absolutely nothing good about it the acting is among the worst i have ever seen what is really amazing is that everyone is awful not just a few here and there everyone the direction is a joke the low budget is [UNK] [UNK] the score is awful i wouldnt say the movie was [UNK] [UNK] [UNK] would be a more [UNK] [UNK] it [UNK] [UNK] [UNK] [UNK] and [UNK] [UNK] dumb dumb dumb it is not scary at all the special effects are [UNK] lame [UNK] bad throughout the writing was [UNK] bad the cinematography is real cheap looking and very [UNK] sometimes and the [UNK] is [UNK] again what really does the movie in is how badly all the actors are cheesy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n\nOriginal:  b'This film concerns a very young girl, Cassie, (Melissa Sagemiller) who leaves her family and heads off to become a college freshman. One night Cassie and her friends decide to go to a wild party with plenty of drinking and dancing and Cassie is riding with her boyfriend who she likes but never told him she loved him. As Cassie was driving, a car was stopped in the middle of the road and she was unable to avoid an accident and as a result there is a bloody loss of lives along with her boyfriend. Cassie becomes very emotionally upset and has nightmares which cause her to have hallucinations about her boyfriend coming back to life and encounters men trying to murder her and she is struggling to find out who her real friends are, who wants her dead and will she survive this entire horror ordeal. Cassie dreams she is being made love to by her boyfriend after he died and finds another guy in her bed and is told she was asking him to make love. This is a way out film, and not very good at all.'\nRound-trip:  this film [UNK] a very young girl [UNK] [UNK] [UNK] who leaves her family and [UNK] off to become a [UNK] [UNK] one night [UNK] and her friends [UNK] to go to a [UNK] [UNK] with plenty of [UNK] and [UNK] and [UNK] is [UNK] with her [UNK] who she [UNK] but never told him she loved him as [UNK] was [UNK] a car was [UNK] in the middle of the [UNK] and she was [UNK] to avoid an [UNK] and as a result there is a [UNK] [UNK] of lives along with her [UNK] [UNK] becomes very [UNK] [UNK] and has [UNK] which [UNK] her to have [UNK] about her [UNK] coming back to life and [UNK] men trying to murder her and she is [UNK] to find out who her real friends are who wants her dead and will she [UNK] this entire horror [UNK] [UNK] [UNK] she is being made love to by her [UNK] after he [UNK] and finds another guy in her [UNK] and is told she was [UNK] him to make love this is a way out film and not very good at all                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n\n"
     ]
    }
   ],
   "source": [
    "for example, label in trainDataset.take(1):\r\n",
    "    encodedExample = encoder(example)[:3].numpy()\r\n",
    "    print(encodedExample)\r\n",
    "\r\n",
    "for example, label in trainDataset.take(1):\r\n",
    "    encodedExample = encoder(example)[:3].numpy()\r\n",
    "    for n in range(3):\r\n",
    "        print('Original: ', example[n].numpy())\r\n",
    "        print('Round-trip: ', ' '.join(vocab[encodedExample[n]]))\r\n",
    "        print()"
   ]
  },
  {
   "source": [
    "Implementando arquitectura para RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True\n",
    "    ),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "print([layer.supports_masking for layer in model.layers])\n"
   ]
  },
  {
   "source": [
    "Viendo si funciona la solución"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Texto sin padding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.00460901], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "sampleText = ('The movie was cool. The animation and the graphics '\n",
    "              'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sampleText]))\n",
    "predictions[0]"
   ]
  },
  {
   "source": [
    "Texto con padding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.00460901], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sampleText, padding]))\n",
    "predictions[0]"
   ]
  },
  {
   "source": [
    "Compilando la solución"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "Entrenando modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainDataset, epochs=10,\n",
    "                    validation_data=testDataset, validation_steps=30)\n",
    "\n",
    "testLoss, testAcc = model.evaluate(testDataset)\n",
    "print('Test Loss: ', testLoss)\n",
    "print('Test Accuracy: ', testAcc)"
   ]
  },
  {
   "source": [
    "# Resultados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plotGraphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plotGraphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "source": [
    "![](graphs.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Una de las ventajas de usar Tensorflow es exportar este modelo para no cargar nuevamente el entrenamiento y gastar tiempo. Así, para poder usarlo existen varias formas, pero dado que mi objetivo es usarlo en una plataforma web, utilice Flask. Este framework de python permite hacer una comunicación TCP/IP de forma fácil y sencilla. Cree una directiva para que Flask obtuviera el texto a analizar y el modelo se encarga de predicir qué tan bueno o malo es, como si lo estuviera usando en local."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "De esta forma, la implementación para el módulo de comentarios queda de la siguiente forma.\n",
    "\n",
    "![Home](Home.jpg)\n",
    "\n",
    "Después de escribir texto, sale el siguiente resultado.\n",
    "\n",
    "![Comment](Comment.jpg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}